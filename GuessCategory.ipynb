{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7b72032c-f791-48f0-a45b-bd994a98bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Train total: 80\n",
      ">> Test total: 20\n",
      ">> Training data length: 80\n",
      ">> Validation data length: 20\n",
      ">> Test data length: 100\n",
      "FBFIC009030\n",
      "THE HARD-BITTEN CHAMPION OF BRITISH HEROIC FANTASY' - Joe Abercrombie 'HEROISM AND HEARTBREAK . . . GEMMELL IS ADRENALINE WITH SOUL' - Brent Weeks It is three hundred years since the world toppled on its axis and  civilisation was destroyed. In this savagely reshaped world ruled by  brigands and war-makers, a rider seeks a lost city. Pursuing a dream to  calm the violence in his soul, Jon Shannow, the brigand slayer, desires  only peace. But from the Plague Lands emerges a fresh terror.The  Lord of the Pit and his hellborn army seek to plunge mankind into a new demonic era. Seemingly invincible, they make a fatal mistake: they take  Shannow's woman for blood sacrifice. And find themselves facing the  deadliest warrior of the new age. Jon Shannow - the Jerusalem Man.Novels by David GemmellThe Drenai seriesLegend The King Beyond the GateWaylanderQuest For Lost Heroes Waylander II: In the Realm of the WolfThe First Chronicles of Druss the LegendJon Shannow seriesWolf in ShadowThe Last GuardianBloodstone Stones of Power Ghost KingLast Sword of Power Hawk Queen seriesIronhand's DaughterThe Hawk Eternal Ancient Greece novelsLion of MacedonDark Prince Other novelsKnights of Dark RenownMorningstar\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "items_total = 100 #10000\n",
    "cats_total = 48 # 1174 para 10K | 48 para 100\n",
    "split = 0.8\n",
    "train_total = int(items_total * split)\n",
    "test_total = int(items_total - train_total)\n",
    "\n",
    "print (\">> Train total: \"+str(train_total))\n",
    "print (\">> Test total: \"+str(test_total))\n",
    "\n",
    "# data arrays\n",
    "train_data = []\n",
    "train_labels = []\n",
    "validation_data = []\n",
    "validation_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "# Creamos dir con las categorias\n",
    "newpath = '/categories' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "# Folders de train y test\n",
    "newpath_train = '/categories/train'\n",
    "newpath_test = '/categories/test'\n",
    "\n",
    "# Obtenemos train y validation\n",
    "with open('/Users/raulrodriguez_demarque/demarque/market/categories_100.csv') as csvfile:\n",
    "  reader = csv.reader(csvfile, delimiter=',')\n",
    "  step = 0\n",
    "  for row in reader:\n",
    "    if step < train_total:\n",
    "      train_data.append(row[2].replace('\\n', ' ').replace('\\r', ''))\n",
    "      train_labels.append(row[1])\n",
    "    else:\n",
    "      validation_data.append(row[2].replace('\\n', ' ').replace('\\r', ''))\n",
    "      validation_labels.append(row[1])\n",
    "    step += 1\n",
    "\n",
    "# Ahora obtenemos el test\n",
    "with open('/Users/raulrodriguez_demarque/demarque/market/categories_100.csv') as csvfile_test:\n",
    "    reader_test = csv.reader(csvfile_test, delimiter=',')\n",
    "    for row_test in reader_test:\n",
    "      test_data.append(row[2].replace('\\n', ' ').replace('\\r', ' '))\n",
    "      test_labels.append(row[1])\n",
    "\n",
    "print(\">> Training data length: \"+str(len(train_data)))\n",
    "print(\">> Validation data length: \"+str(len(validation_data)))\n",
    "print(\">> Test data length: \"+str(len(test_data)))\n",
    "print(train_labels[0])\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "59968852-e7db-4ecb-8332-c4883edd697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')\n",
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a2fbbb34-c247-4f0d-be5e-fe15e5037b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> raw_train_ds: <_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>\n",
      ">> ITEM--------------------------------\n",
      "tf.Tensor(b\"THE HARD-BITTEN CHAMPION OF BRITISH HEROIC FANTASY' - Joe Abercrombie 'HEROISM AND HEARTBREAK . . . GEMMELL IS ADRENALINE WITH SOUL' - Brent Weeks It is three hundred years since the world toppled on its axis and  civilisation was destroyed. In this savagely reshaped world ruled by  brigands and war-makers, a rider seeks a lost city. Pursuing a dream to  calm the violence in his soul, Jon Shannow, the brigand slayer, desires  only peace. But from the Plague Lands emerges a fresh terror.The  Lord of the Pit and his hellborn army seek to plunge mankind into a new demonic era. Seemingly invincible, they make a fatal mistake: they take  Shannow's woman for blood sacrifice. And find themselves facing the  deadliest warrior of the new age. Jon Shannow - the Jerusalem Man.Novels by David GemmellThe Drenai seriesLegend The King Beyond the GateWaylanderQuest For Lost Heroes Waylander II: In the Realm of the WolfThe First Chronicles of Druss the LegendJon Shannow seriesWolf in ShadowThe Last GuardianBloodstone Stones of Power Ghost KingLast Sword of Power Hawk Queen seriesIronhand's DaughterThe Hawk Eternal Ancient Greece novelsLion of MacedonDark Prince Other novelsKnights of Dark RenownMorningstar\", shape=(), dtype=string)\n",
      "tf.Tensor(b'FBFIC009030', shape=(), dtype=string)\n",
      ">> ITEM--------------------------------\n",
      "tf.Tensor(b'In a remote mountain academy, the politically expendable younger sons of the Great Houses study for an extraordinary task. Most will fail, some will die, but the reward for the dedicated few is great: mastery of the andat, and the rank of Poet. Thanks to these men - part sorcerers, part scholars - the great city-states of the Khaiem enjoy wealth and power beyond measure, and the greatest of them all is Saraykeht: glittering jewel of the Summer Cities.There are those in the world, however, who envy such wealth. There are great riches to be had in the Summer and Winter Cities, and only the threat of the andat unleashed holds the enemies of the Khaiem in check. Conflict is brewing in the world. Alliances will be broken and friends betrayed. The lowly will be raised up, the mighty will fall and innocents will be slaughtered. And two men, bound to each other by an act of kindness and an act of brutality, may be all that stands between the civilised world and war. War and something worse . . .', shape=(), dtype=string)\n",
      "tf.Tensor(b'FBFIC009000', shape=(), dtype=string)\n",
      ">> ITEM--------------------------------\n",
      "tf.Tensor(b\"For my money, Ken MacLeod is the current champion of the very smartest kind of New Space Opera... every variation on his themes produces something worth re-reading.' - LOCUS'MacLeod manages big Ideas (political and futurological) and propulsive action without short-changing either side of that classic science-fictional tension-of-opposites.' - LOCUSDIE FOR THE COMPANY, LIVE FOR THE PAYAnd the ultimate pay-off is DH-17, an Earth-like planet hundreds of light years from human habitation.Ruthless corporations vie over the prize remotely, and war is in full swing. But soldiers recruited to fight in the extremities of deep space come with their own problems: from A.I. minds in full rebellion, to Carlos 'the Terrorist' and his team of dead mercenaries, reincarnated from a bloodier period in earth's history for one purpose only - to kill.But as old rivalries emerge and new ones form, Carlos must decide whether he's willing for fight for the company or die for himself.Ken MacLeod continues the Corporation Wars trilogy in this action-packed science fiction adventure told against a backdrop of interstellar drone warfare, virtual reality, and an A.I. revolution.Books by Ken MacLeod:Fall RevolutionThe Star FractionThe Stone CanalThe Cassini DivisionThe Sky RoadEngines of LightCosmonaut KeepDark LightEngine CityCorporation Wars TrilogyDissidenceInsurgenceEmergenceNovelsThe Human FrontNewton's WakeLearning the WorldThe Execution ChannelThe Restoration GameIntrusionDescent\", shape=(), dtype=string)\n",
      "tf.Tensor(b'FBFIC028010', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Make a few datasets\n",
    "\n",
    "#Convertimos nuestros datos a numpy arrays DO I NEED THIS?\n",
    "np_train_labels = np.array(train_labels)\n",
    "np_train_data = np.array(train_data)\n",
    "\n",
    "np_validation_labels = np.array(validation_labels)\n",
    "np_validation_data = np.array(validation_data)\n",
    "\n",
    "np_test_labels = np.array(test_labels)\n",
    "np_test_data = np.array(test_data)\n",
    "\n",
    "# Este tampoco adapta pero hay que probarlo XD\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "  (np_train_data, np_train_labels)\n",
    ")\n",
    "raw_validation_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (np_validation_data, np_validation_labels)\n",
    ")\n",
    "raw_test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (np_test_data, np_test_labels)\n",
    ")\n",
    "\n",
    "\n",
    "# no veo la diferencia de esto contra hacerlo directo (sin tf.convert_to_tensor)\n",
    "print(\">> raw_train_ds: \"+str(raw_train_ds))\n",
    "\n",
    "\n",
    "\n",
    "for index, item in enumerate(raw_train_ds):  # only take first element of dataset\n",
    "    print(\">> ITEM--------------------------------\")\n",
    "    # item[0].ensure_shape(None,)\n",
    "    # item[1].ensure_shape(None,)\n",
    "    print(item[0])\n",
    "    print(item[1])\n",
    "    if index == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0fab2754-663c-48d9-8b31-b85c28377484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "15ff45d9-3756-4290-92ae-a3e64253e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    encoding=\"utf-8\",\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b872fd46-fe66-48df-bc20-aa6e1411a227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> raw_train_ds: <_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>\n",
      ">> vectorize_layer adapted: <TextVectorization name=text_vectorization_28, built=False>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 05:47:02.583523: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(\">> raw_train_ds: \"+str(raw_train_ds))\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "#test, maybe remove\n",
    "# batch_size = 32\n",
    "# raw_train_ds = raw_train_ds.batch(batch_size)\n",
    "\n",
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "\n",
    "# Test\n",
    "texts_only = []\n",
    "for index, item in enumerate(train_text):\n",
    "    # estoy pensando que quiero adaptar un tensor, no un string y ese puede ser el problema\n",
    "    # print(index)\n",
    "    # print(item.numpy().decode('ascii')) # esto no sirva para obtener el string\n",
    "    # if index == 2:\n",
    "    #     break\n",
    "    texts_only.append(item.numpy().decode('utf-8'))\n",
    "\n",
    "vectorize_layer.adapt(texts_only)\n",
    "\n",
    "# print(\">> train_text: \"+str(train_text))\n",
    "# vectorize_layer.adapt(train_text)\n",
    "# # print(\">> train_text: \"+str(train_text)) # esto no funciona\n",
    "# # print(\">> train_text: \"+str(train_data))\n",
    "\n",
    "# # Esto funciona pero me da built=False\n",
    "# # vectorize_layer.adapt(train_data)\n",
    "print(\">> vectorize_layer adapted: \"+str(vectorize_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b5c4beb7-e685-40f8-8666-7f07af009f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c6e3d8ce-43b6-4325-8fa7-27eb522579d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 06:01:23.896124: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Attempting to slice scalar input.\n",
      "2024-04-25 06:01:23.896144: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Attempting to slice scalar input.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Attempting to slice scalar input. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# retrieve a batch (of 32 reviews and labels) from the dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m text_batch, label_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(raw_train_ds))\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>> text_batch[0]: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[43mtext_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>> label_batch[0]: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(label_batch[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      6\u001b[0m first_review, first_label \u001b[38;5;241m=\u001b[39m text_batch[\u001b[38;5;241m0\u001b[39m], label_batch[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Attempting to slice scalar input. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "print(\">> text_batch[0]: \"+str(text_batch[0]))\n",
    "print(\">> label_batch[0]: \"+str(label_batch[0]))\n",
    "\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b55e0a6b-b089-4341-9146-958d761c2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_validation_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b5b22a84-d555-4151-a154-726c9218f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a03672c3-050c-4735-9e85-8339d2dc232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features, embedding_dim),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  # layers.Dense(1, activation='sigmoid')\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(cats_total)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "72946459-2298-459d-b09d-c87e6a425206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "bd6bb149-2b1e-45e0-9ae1-bed81dd1b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 05:47:44.488438: W tensorflow/core/framework/op_kernel.cc:1816] OP_REQUIRES failed at cast_op.cc:122 : UNIMPLEMENTED: Cast string to float is not supported\n",
      "2024-04-25 05:47:44.488462: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "{{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to float is not supported [Op:Cast] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/optree/ops.py:594\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    592\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    593\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: {{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to float is not supported [Op:Cast] name: "
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ab2a5-9fc6-4810-9876-13373269ef50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
