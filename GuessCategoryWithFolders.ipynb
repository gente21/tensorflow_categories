{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b72032c-f791-48f0-a45b-bd994a98bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# Creamos dir con las categorias\n",
    "newpath = './categories' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "# Folders de train y test\n",
    "newpath_train = newpath+'/train'\n",
    "newpath_test = newpath+'/test'\n",
    "\n",
    "def save_file(folder, text):\n",
    "    with open(folder, 'w') as text_file:\n",
    "        print(text, file=text_file)\n",
    "\n",
    "# Obtenemos train\n",
    "def csv_to_folders(source_file, target_folder):\n",
    "    with open(source_file) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        step = 0\n",
    "        for row in reader:\n",
    "            cat_folder = target_folder+'/'+row[0]\n",
    "            target_file = cat_folder+'/'+str(step)+'_'+row[0]+'.txt'\n",
    "            if not os.path.exists(cat_folder):\n",
    "                os.makedirs(cat_folder)\n",
    "                save_file(target_file, row[1])\n",
    "            else:\n",
    "                save_file(target_file, row[1])\n",
    "            step += 1\n",
    "\n",
    "csv_to_folders('/Users/raulrodriguez_demarque/demarque/market/cats_NOSEK_100_only.csv', newpath_train)\n",
    "csv_to_folders('/Users/raulrodriguez_demarque/demarque/market/cats_NOSEK_test_20.csv', newpath_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f7a6fb-c507-4a0f-8cd2-ed1fcbaf14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51567 files belonging to 522 classes.\n",
      "Using 41254 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 6\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    newpath_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    label_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59968852-e7db-4ecb-8332-c4883edd697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2da9be3-6984-40ea-80a5-9235f858f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------- SEPARATOR ----------------------------\n",
      "Text b'On a Muggy night in Mumbai Penguin  Mahesh Dattani  A playwright of world statureMario Relich WasafiriOn a Muggy Night in Mumbai is the first contemporary Indian play to openly tackle gay themes of love partnership trust and betrayal Kamleshyoung gay and clinically depressedinvites his friends home ostensibly for an evening of camaraderie However with the arrival of his sister and her fianc a series of dramatic confrontations is set into motion leading to startling revelations and unexpected catharsisAt last we have a playwright who gives sixty million Englishspeaking Indians an identityAlyque PadamseePowerful and disturbingThe New York Times\\n'\n",
      "Category [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Text b'The Tao Of Health Sex and Longevity Atria Books  Daniel Reid  With a detailed introduction to the ancient philosophical ethical and religious Chinese practice of Taoism The Tao of Health Sex and Longevity is a unique comprehensive and practical selfhelp guide to live a balanced and positive Taoist lifestyleWritten by a Westerner for the Western mind The Tao of Health Sex and Longevity is perfect for the modern reader interested in exploring the balanced and holistic health care system used by Chinese physicians martial artists and meditators for over  years Drawing on his extensive personal experience and research from original sources author Daniel Reid covers all aspects of the healthy Taoist lifestyle delivering concise information and instruction on diet and nutrition fasting breathing and exercise sexual health medicine and meditation Featuring helpful charts and illustrations The Tao of Health Sex and Longevity makes the ancient practice easier to understand and more applicable to a modern Western audience than ever before\\n'\n",
      "Category [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Text b'Living Yogacara Wisdom Publications  Tagawa Shunei  Yogacara is an influential school of Buddhist philosophy and psychology that stems from the early Indian Mahayana Buddhist tradition The Yogacara view is based on the fundamental truth that there is nothing in the realm of human experience that is not interpreted by and dependent upon the mind Yogacara Buddhism was unable to sustain the same level of popularity as other Buddhist schools in India Tibet and East Asia but its teachings on the nature of consciousness profoundly impacted the successive developments of Buddhism Yogacara served as the basis for the development of the doctrines of karma and liberation in many other schools In this refreshingly accessible study Tagawa Shunei makes sense of Yogacaras subtleties and complexities with insight and clarity He shows us that Yogacara masters comprehend and express everyday experiences that we all take for granted yet struggle to explain Eloquent and approachable Living Yogacara deepens the readers understanding of the development of Buddhisms interpretation of the human psyche\\n'\n",
      "Category [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "----------------------- SEPARATOR ----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 07:43:56.999923: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------- SEPARATOR ----------------------------\")\n",
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(\"Text\", text_batch.numpy()[i])\n",
    "    print(\"Category\", label_batch.numpy()[i])\n",
    "print(\"----------------------- SEPARATOR ----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27dbcc00-2353-45e8-86c9-01604f19e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Label 0 corresponds to FBANT000000\n",
      "- Label 1 corresponds to FBANT002000\n",
      "- Label 2 corresponds to FBANT016000\n",
      "- Label 3 corresponds to FBARC000000\n",
      "- Label 4 corresponds to FBARC005000\n",
      "- Label 5 corresponds to FBARC005070\n",
      "- Label 6 corresponds to FBART000000\n",
      "- Label 7 corresponds to FBART000000N\n",
      "- Label 8 corresponds to FBART001000\n",
      "- Label 9 corresponds to FBART009000\n",
      "- Label 10 corresponds to FBART010000\n",
      "- Label 11 corresponds to FBART020000\n",
      "- Label 12 corresponds to FBART028000\n",
      "- Label 13 corresponds to FBART050000\n",
      "- Label 14 corresponds to FBART060000\n",
      "- Label 15 corresponds to FBBIO000000\n",
      "- Label 16 corresponds to FBBIO001000\n",
      "- Label 17 corresponds to FBBIO001000N\n",
      "- Label 18 corresponds to FBBIO004000\n",
      "- Label 19 corresponds to FBBIO005000\n",
      "- Label 20 corresponds to FBBIO006000\n",
      "- Label 21 corresponds to FBBIO007000\n",
      "- Label 22 corresponds to FBBIO008000\n",
      "- Label 23 corresponds to FBBIO010000\n",
      "- Label 24 corresponds to FBBIO011000\n",
      "- Label 25 corresponds to FBBIO013000\n",
      "- Label 26 corresponds to FBBIO014000\n",
      "- Label 27 corresponds to FBBIO015000\n",
      "- Label 28 corresponds to FBBIO016000\n",
      "- Label 29 corresponds to FBBIO017000\n",
      "- Label 30 corresponds to FBBIO018000\n",
      "- Label 31 corresponds to FBBIO022000\n",
      "- Label 32 corresponds to FBBIO023000\n",
      "- Label 33 corresponds to FBBIO024000\n",
      "- Label 34 corresponds to FBBIO026000\n",
      "- Label 35 corresponds to FBBUS000000\n",
      "- Label 36 corresponds to FBBUS007000\n",
      "- Label 37 corresponds to FBBUS012000\n",
      "- Label 38 corresponds to FBBUS020000\n",
      "- Label 39 corresponds to FBBUS023000\n",
      "- Label 40 corresponds to FBBUS025000\n",
      "- Label 41 corresponds to FBBUS027000\n",
      "- Label 42 corresponds to FBBUS030000\n",
      "- Label 43 corresponds to FBBUS035000\n",
      "- Label 44 corresponds to FBBUS036000\n",
      "- Label 45 corresponds to FBBUS037020\n",
      "- Label 46 corresponds to FBBUS041000\n",
      "- Label 47 corresponds to FBBUS043000\n",
      "- Label 48 corresponds to FBBUS046000\n",
      "- Label 49 corresponds to FBBUS050000\n",
      "- Label 50 corresponds to FBBUS060000\n",
      "- Label 51 corresponds to FBBUS063000\n",
      "- Label 52 corresponds to FBBUS068000\n",
      "- Label 53 corresponds to FBBUS069000\n",
      "- Label 54 corresponds to FBBUS069020\n",
      "- Label 55 corresponds to FBBUS069030\n",
      "- Label 56 corresponds to FBBUS070000\n",
      "- Label 57 corresponds to FBBUS071000\n",
      "- Label 58 corresponds to FBBUS078000N\n",
      "- Label 59 corresponds to FBBUS081000\n",
      "- Label 60 corresponds to FBBUS083000\n",
      "- Label 61 corresponds to FBBUS092000\n",
      "- Label 62 corresponds to FBCGN000000\n",
      "- Label 63 corresponds to FBCKB000000\n",
      "- Label 64 corresponds to FBCKB004000\n",
      "- Label 65 corresponds to FBCKB010000N\n",
      "- Label 66 corresponds to FBCKB014000\n",
      "- Label 67 corresponds to FBCKB023000\n",
      "- Label 68 corresponds to FBCKB024000\n",
      "- Label 69 corresponds to FBCKB039000\n",
      "- Label 70 corresponds to FBCKB041000\n",
      "- Label 71 corresponds to FBCKB070000\n",
      "- Label 72 corresponds to FBCKB071000\n",
      "- Label 73 corresponds to FBCKB088000\n",
      "- Label 74 corresponds to FBCKB100000\n",
      "- Label 75 corresponds to FBCKB101000\n",
      "- Label 76 corresponds to FBCKB105000\n",
      "- Label 77 corresponds to FBCOM000000\n",
      "- Label 78 corresponds to FBCOM051010\n",
      "- Label 79 corresponds to FBCRA000000\n",
      "- Label 80 corresponds to FBCRA004000\n",
      "- Label 81 corresponds to FBCRA010000N\n",
      "- Label 82 corresponds to FBCRA014000\n",
      "- Label 83 corresponds to FBCRA015000\n",
      "- Label 84 corresponds to FBCRA020000N\n",
      "- Label 85 corresponds to FBCRA022000\n",
      "- Label 86 corresponds to FBCRA030000N\n",
      "- Label 87 corresponds to FBCRA035000\n",
      "- Label 88 corresponds to FBDES000000\n",
      "- Label 89 corresponds to FBDRA000000\n",
      "- Label 90 corresponds to FBEDU000000\n",
      "- Label 91 corresponds to FBEDU010000N\n",
      "- Label 92 corresponds to FBEDU015000\n",
      "- Label 93 corresponds to FBEDU023000\n",
      "- Label 94 corresponds to FBEDU024000\n",
      "- Label 95 corresponds to FBEDU026000\n",
      "- Label 96 corresponds to FBEDU030000N\n",
      "- Label 97 corresponds to FBEDU040000N\n",
      "- Label 98 corresponds to FBEDU042000\n",
      "- Label 99 corresponds to FBFAM000000\n",
      "- Label 100 corresponds to FBFAM001000\n",
      "- Label 101 corresponds to FBFAM003000\n",
      "- Label 102 corresponds to FBFAM010000\n",
      "- Label 103 corresponds to FBFAM012000\n",
      "- Label 104 corresponds to FBFAM016000\n",
      "- Label 105 corresponds to FBFAM019000\n",
      "- Label 106 corresponds to FBFAM020000N\n",
      "- Label 107 corresponds to FBFAM023000\n",
      "- Label 108 corresponds to FBFAM029000\n",
      "- Label 109 corresponds to FBFAM030000\n",
      "- Label 110 corresponds to FBFAM032000\n",
      "- Label 111 corresponds to FBFAM033000\n",
      "- Label 112 corresponds to FBFAM040000N\n",
      "- Label 113 corresponds to FBFIC000000\n",
      "- Label 114 corresponds to FBFIC002000\n",
      "- Label 115 corresponds to FBFIC003000\n",
      "- Label 116 corresponds to FBFIC004000\n",
      "- Label 117 corresponds to FBFIC005000\n",
      "- Label 118 corresponds to FBFIC006000\n",
      "- Label 119 corresponds to FBFIC009000\n",
      "- Label 120 corresponds to FBFIC009010N\n",
      "- Label 121 corresponds to FBFIC009020\n",
      "- Label 122 corresponds to FBFIC009030\n",
      "- Label 123 corresponds to FBFIC009040\n",
      "- Label 124 corresponds to FBFIC010000\n",
      "- Label 125 corresponds to FBFIC012000\n",
      "- Label 126 corresponds to FBFIC012001N\n",
      "- Label 127 corresponds to FBFIC014000\n",
      "- Label 128 corresponds to FBFIC014020N\n",
      "- Label 129 corresponds to FBFIC014030N\n",
      "- Label 130 corresponds to FBFIC014040N\n",
      "- Label 131 corresponds to FBFIC014050N\n",
      "- Label 132 corresponds to FBFIC015000\n",
      "- Label 133 corresponds to FBFIC016000\n",
      "- Label 134 corresponds to FBFIC019000\n",
      "- Label 135 corresponds to FBFIC021000\n",
      "- Label 136 corresponds to FBFIC022000\n",
      "- Label 137 corresponds to FBFIC022010\n",
      "- Label 138 corresponds to FBFIC022020\n",
      "- Label 139 corresponds to FBFIC022030\n",
      "- Label 140 corresponds to FBFIC022040\n",
      "- Label 141 corresponds to FBFIC022050\n",
      "- Label 142 corresponds to FBFIC022060\n",
      "- Label 143 corresponds to FBFIC024000\n",
      "- Label 144 corresponds to FBFIC024020N\n",
      "- Label 145 corresponds to FBFIC027000\n",
      "- Label 146 corresponds to FBFIC027010\n",
      "- Label 147 corresponds to FBFIC027020\n",
      "- Label 148 corresponds to FBFIC027030\n",
      "- Label 149 corresponds to FBFIC027040\n",
      "- Label 150 corresponds to FBFIC027050\n",
      "- Label 151 corresponds to FBFIC027070\n",
      "- Label 152 corresponds to FBFIC027080\n",
      "- Label 153 corresponds to FBFIC027100\n",
      "- Label 154 corresponds to FBFIC027110\n",
      "- Label 155 corresponds to FBFIC027120\n",
      "- Label 156 corresponds to FBFIC028000\n",
      "- Label 157 corresponds to FBFIC028010\n",
      "- Label 158 corresponds to FBFIC028020\n",
      "- Label 159 corresponds to FBFIC028030\n",
      "- Label 160 corresponds to FBFIC028040\n",
      "- Label 161 corresponds to FBFIC028050\n",
      "- Label 162 corresponds to FBFIC028060N\n",
      "- Label 163 corresponds to FBFIC029000\n",
      "- Label 164 corresponds to FBFIC030000\n",
      "- Label 165 corresponds to FBFIC031000\n",
      "- Label 166 corresponds to FBFIC032000\n",
      "- Label 167 corresponds to FBFIC033000\n",
      "- Label 168 corresponds to FBFIC034000\n",
      "- Label 169 corresponds to FBFIC041000\n",
      "- Label 170 corresponds to FBFIC042000\n",
      "- Label 171 corresponds to FBFIC042030\n",
      "- Label 172 corresponds to FBFIC042040\n",
      "- Label 173 corresponds to FBFIC042060\n",
      "- Label 174 corresponds to FBFIC044000\n",
      "- Label 175 corresponds to FBFIC047000\n",
      "- Label 176 corresponds to FBFIC049020\n",
      "- Label 177 corresponds to FBFIC060000N\n",
      "- Label 178 corresponds to FBFOR000000\n",
      "- Label 179 corresponds to FBGAM000000\n",
      "- Label 180 corresponds to FBGAR000000\n",
      "- Label 181 corresponds to FBGAR001000N\n",
      "- Label 182 corresponds to FBHEA000000\n",
      "- Label 183 corresponds to FBHEA003000\n",
      "- Label 184 corresponds to FBHEA006000\n",
      "- Label 185 corresponds to FBHEA014000\n",
      "- Label 186 corresponds to FBHEA016000\n",
      "- Label 187 corresponds to FBHEA039000\n",
      "- Label 188 corresponds to FBHEA041000\n",
      "- Label 189 corresponds to FBHEA042000\n",
      "- Label 190 corresponds to FBHIS000000\n",
      "- Label 191 corresponds to FBHIS000000N\n",
      "- Label 192 corresponds to FBHIS001000\n",
      "- Label 193 corresponds to FBHIS001000N\n",
      "- Label 194 corresponds to FBHIS002000\n",
      "- Label 195 corresponds to FBHIS003000\n",
      "- Label 196 corresponds to FBHIS004000\n",
      "- Label 197 corresponds to FBHIS006000\n",
      "- Label 198 corresponds to FBHIS008000\n",
      "- Label 199 corresponds to FBHIS010000\n",
      "- Label 200 corresponds to FBHIS010010\n",
      "- Label 201 corresponds to FBHIS013000\n",
      "- Label 202 corresponds to FBHIS014000\n",
      "- Label 203 corresponds to FBHIS015000\n",
      "- Label 204 corresponds to FBHIS018000\n",
      "- Label 205 corresponds to FBHIS021000\n",
      "- Label 206 corresponds to FBHIS026000\n",
      "- Label 207 corresponds to FBHIS027000\n",
      "- Label 208 corresponds to FBHIS027090\n",
      "- Label 209 corresponds to FBHIS027100\n",
      "- Label 210 corresponds to FBHIS028000\n",
      "- Label 211 corresponds to FBHIS032000\n",
      "- Label 212 corresponds to FBHIS033000\n",
      "- Label 213 corresponds to FBHIS036000\n",
      "- Label 214 corresponds to FBHIS036010\n",
      "- Label 215 corresponds to FBHIS036010N\n",
      "- Label 216 corresponds to FBHIS036020\n",
      "- Label 217 corresponds to FBHIS036020N\n",
      "- Label 218 corresponds to FBHIS036030\n",
      "- Label 219 corresponds to FBHIS036050\n",
      "- Label 220 corresponds to FBHIS036120\n",
      "- Label 221 corresponds to FBHIS037010\n",
      "- Label 222 corresponds to FBHIS037020\n",
      "- Label 223 corresponds to FBHIS037060\n",
      "- Label 224 corresponds to FBHIS037070\n",
      "- Label 225 corresponds to FBHIS043000\n",
      "- Label 226 corresponds to FBHIS054000\n",
      "- Label 227 corresponds to FBHOM000000\n",
      "- Label 228 corresponds to FBHUM000000\n",
      "- Label 229 corresponds to FBHUM000000N\n",
      "- Label 230 corresponds to FBHUM003000\n",
      "- Label 231 corresponds to FBHUM009000\n",
      "- Label 232 corresponds to FBHUM100000N\n",
      "- Label 233 corresponds to FBJNF000000\n",
      "- Label 234 corresponds to FBJNF001000\n",
      "- Label 235 corresponds to FBJNF003000\n",
      "- Label 236 corresponds to FBJNF006000\n",
      "- Label 237 corresponds to FBJNF007000\n",
      "- Label 238 corresponds to FBJNF007040\n",
      "- Label 239 corresponds to FBJNF025000\n",
      "- Label 240 corresponds to FBJNF028000\n",
      "- Label 241 corresponds to FBJNF036000N\n",
      "- Label 242 corresponds to FBJNF038000\n",
      "- Label 243 corresponds to FBJNF044000N\n",
      "- Label 244 corresponds to FBJNF049000\n",
      "- Label 245 corresponds to FBJNF049060\n",
      "- Label 246 corresponds to FBJNF050000\n",
      "- Label 247 corresponds to FBJNF051000\n",
      "- Label 248 corresponds to FBJNF051000N\n",
      "- Label 249 corresponds to FBJNF053000\n",
      "- Label 250 corresponds to FBJUV000000\n",
      "- Label 251 corresponds to FBJUV000000N\n",
      "- Label 252 corresponds to FBJUV001000\n",
      "- Label 253 corresponds to FBJUV001010\n",
      "- Label 254 corresponds to FBJUV002000\n",
      "- Label 255 corresponds to FBJUV002050\n",
      "- Label 256 corresponds to FBJUV002070\n",
      "- Label 257 corresponds to FBJUV002130\n",
      "- Label 258 corresponds to FBJUV005000\n",
      "- Label 259 corresponds to FBJUV007000\n",
      "- Label 260 corresponds to FBJUV009000\n",
      "- Label 261 corresponds to FBJUV009000N\n",
      "- Label 262 corresponds to FBJUV009001N\n",
      "- Label 263 corresponds to FBJUV010000N\n",
      "- Label 264 corresponds to FBJUV012030\n",
      "- Label 265 corresponds to FBJUV013000\n",
      "- Label 266 corresponds to FBJUV013060\n",
      "- Label 267 corresponds to FBJUV013070\n",
      "- Label 268 corresponds to FBJUV014000\n",
      "- Label 269 corresponds to FBJUV016000\n",
      "- Label 270 corresponds to FBJUV016110\n",
      "- Label 271 corresponds to FBJUV016150\n",
      "- Label 272 corresponds to FBJUV017000\n",
      "- Label 273 corresponds to FBJUV018000\n",
      "- Label 274 corresponds to FBJUV019000\n",
      "- Label 275 corresponds to FBJUV022000\n",
      "- Label 276 corresponds to FBJUV026000\n",
      "- Label 277 corresponds to FBJUV028000\n",
      "- Label 278 corresponds to FBJUV029000\n",
      "- Label 279 corresponds to FBJUV030000\n",
      "- Label 280 corresponds to FBJUV030060\n",
      "- Label 281 corresponds to FBJUV031000\n",
      "- Label 282 corresponds to FBJUV031060\n",
      "- Label 283 corresponds to FBJUV032000\n",
      "- Label 284 corresponds to FBJUV033000\n",
      "- Label 285 corresponds to FBJUV033010\n",
      "- Label 286 corresponds to FBJUV033080\n",
      "- Label 287 corresponds to FBJUV033240\n",
      "- Label 288 corresponds to FBJUV035000\n",
      "- Label 289 corresponds to FBJUV037000\n",
      "- Label 290 corresponds to FBJUV038000\n",
      "- Label 291 corresponds to FBJUV038000N\n",
      "- Label 292 corresponds to FBJUV039000\n",
      "- Label 293 corresponds to FBJUV039020\n",
      "- Label 294 corresponds to FBJUV039030\n",
      "- Label 295 corresponds to FBJUV039050\n",
      "- Label 296 corresponds to FBJUV039060\n",
      "- Label 297 corresponds to FBJUV039090\n",
      "- Label 298 corresponds to FBJUV039140\n",
      "- Label 299 corresponds to FBJUV039190\n",
      "- Label 300 corresponds to FBJUV039230\n",
      "- Label 301 corresponds to FBJUV053000\n",
      "- Label 302 corresponds to FBLAN000000\n",
      "- Label 303 corresponds to FBLAN004000\n",
      "- Label 304 corresponds to FBLAN005000\n",
      "- Label 305 corresponds to FBLAN008000\n",
      "- Label 306 corresponds to FBLAN009000\n",
      "- Label 307 corresponds to FBLAN025000\n",
      "- Label 308 corresponds to FBLAW000000\n",
      "- Label 309 corresponds to FBLAW020000N\n",
      "- Label 310 corresponds to FBLAW044000\n",
      "- Label 311 corresponds to FBLAW051000\n",
      "- Label 312 corresponds to FBLAW075000\n",
      "- Label 313 corresponds to FBLAW116000\n",
      "- Label 314 corresponds to FBLCO000000\n",
      "- Label 315 corresponds to FBLCO002000\n",
      "- Label 316 corresponds to FBLCO009000\n",
      "- Label 317 corresponds to FBLCO010000\n",
      "- Label 318 corresponds to FBLCO011000\n",
      "- Label 319 corresponds to FBLIT000000\n",
      "- Label 320 corresponds to FBMAT000000\n",
      "- Label 321 corresponds to FBMED000000\n",
      "- Label 322 corresponds to FBMED004000\n",
      "- Label 323 corresponds to FBMED039000\n",
      "- Label 324 corresponds to FBMED056000\n",
      "- Label 325 corresponds to FBMED058000\n",
      "- Label 326 corresponds to FBMED078000\n",
      "- Label 327 corresponds to FBMED080000\n",
      "- Label 328 corresponds to FBMED085000\n",
      "- Label 329 corresponds to FBMED089000\n",
      "- Label 330 corresponds to FBMED105000\n",
      "- Label 331 corresponds to FBMUS000000\n",
      "- Label 332 corresponds to FBMUS006000\n",
      "- Label 333 corresponds to FBMUS020000\n",
      "- Label 334 corresponds to FBMUS023000\n",
      "- Label 335 corresponds to FBMUS029000\n",
      "- Label 336 corresponds to FBMUS035000\n",
      "- Label 337 corresponds to FBMUS050000\n",
      "- Label 338 corresponds to FBNAT000000\n",
      "- Label 339 corresponds to FBNAT001000\n",
      "- Label 340 corresponds to FBNAT004000\n",
      "- Label 341 corresponds to FBNAT010000\n",
      "- Label 342 corresponds to FBNAT011000\n",
      "- Label 343 corresponds to FBNAT012000\n",
      "- Label 344 corresponds to FBNFC000000\n",
      "- Label 345 corresponds to FBNLS000000N\n",
      "- Label 346 corresponds to FBOCC000000\n",
      "- Label 347 corresponds to FBOCC002000\n",
      "- Label 348 corresponds to FBOCC002000N\n",
      "- Label 349 corresponds to FBOCC010000\n",
      "- Label 350 corresponds to FBOCC010000N\n",
      "- Label 351 corresponds to FBOCC011000\n",
      "- Label 352 corresponds to FBOCC018000\n",
      "- Label 353 corresponds to FBOCC025000\n",
      "- Label 354 corresponds to FBOCC036000\n",
      "- Label 355 corresponds to FBPER000000\n",
      "- Label 356 corresponds to FBPER001000\n",
      "- Label 357 corresponds to FBPER004000\n",
      "- Label 358 corresponds to FBPER004030\n",
      "- Label 359 corresponds to FBPER005000\n",
      "- Label 360 corresponds to FBPER010000\n",
      "- Label 361 corresponds to FBPER011000\n",
      "- Label 362 corresponds to FBPET000000\n",
      "- Label 363 corresponds to FBPET004000\n",
      "- Label 364 corresponds to FBPHI000000\n",
      "- Label 365 corresponds to FBPHI001000\n",
      "- Label 366 corresponds to FBPHI002000\n",
      "- Label 367 corresponds to FBPHI003000\n",
      "- Label 368 corresponds to FBPHI004000\n",
      "- Label 369 corresponds to FBPHI005000\n",
      "- Label 370 corresponds to FBPHI009000\n",
      "- Label 371 corresponds to FBPHI013000\n",
      "- Label 372 corresponds to FBPHI015000\n",
      "- Label 373 corresponds to FBPHI019000\n",
      "- Label 374 corresponds to FBPHI022000\n",
      "- Label 375 corresponds to FBPHI027000\n",
      "- Label 376 corresponds to FBPHI028000\n",
      "- Label 377 corresponds to FBPHI031000\n",
      "- Label 378 corresponds to FBPHI034000\n",
      "- Label 379 corresponds to FBPHO000000\n",
      "- Label 380 corresponds to FBPHO013000\n",
      "- Label 381 corresponds to FBPOE000000\n",
      "- Label 382 corresponds to FBPOL000000\n",
      "- Label 383 corresponds to FBPOL003000\n",
      "- Label 384 corresponds to FBPOL004000\n",
      "- Label 385 corresponds to FBPOL005000\n",
      "- Label 386 corresponds to FBPOL007000\n",
      "- Label 387 corresponds to FBPOL008000\n",
      "- Label 388 corresponds to FBPOL010000\n",
      "- Label 389 corresponds to FBPOL011000\n",
      "- Label 390 corresponds to FBPOL011010\n",
      "- Label 391 corresponds to FBPOL012000\n",
      "- Label 392 corresponds to FBPOL015000\n",
      "- Label 393 corresponds to FBPOL016000\n",
      "- Label 394 corresponds to FBPOL017000\n",
      "- Label 395 corresponds to FBPOL023000\n",
      "- Label 396 corresponds to FBPOL029000\n",
      "- Label 397 corresponds to FBPOL033000\n",
      "- Label 398 corresponds to FBPOL035000\n",
      "- Label 399 corresponds to FBPOL035010\n",
      "- Label 400 corresponds to FBPOL036000\n",
      "- Label 401 corresponds to FBPOL037000\n",
      "- Label 402 corresponds to FBPOL040000\n",
      "- Label 403 corresponds to FBPOL040010\n",
      "- Label 404 corresponds to FBPOL042000\n",
      "- Label 405 corresponds to FBPOL042020\n",
      "- Label 406 corresponds to FBPSY000000\n",
      "- Label 407 corresponds to FBPSY003000\n",
      "- Label 408 corresponds to FBPSY004000\n",
      "- Label 409 corresponds to FBPSY006000\n",
      "- Label 410 corresponds to FBPSY007000\n",
      "- Label 411 corresponds to FBPSY008000\n",
      "- Label 412 corresponds to FBPSY017000\n",
      "- Label 413 corresponds to FBPSY022000\n",
      "- Label 414 corresponds to FBPSY022020\n",
      "- Label 415 corresponds to FBPSY026000\n",
      "- Label 416 corresponds to FBPSY028000\n",
      "- Label 417 corresponds to FBPSY031000\n",
      "- Label 418 corresponds to FBPSY036000\n",
      "- Label 419 corresponds to FBPSY039000\n",
      "- Label 420 corresponds to FBPSY045000\n",
      "- Label 421 corresponds to FBREF000000\n",
      "- Label 422 corresponds to FBREF008000\n",
      "- Label 423 corresponds to FBREF010000\n",
      "- Label 424 corresponds to FBREF013000\n",
      "- Label 425 corresponds to FBREF015000\n",
      "- Label 426 corresponds to FBREF019000\n",
      "- Label 427 corresponds to FBREF026000\n",
      "- Label 428 corresponds to FBREF028000\n",
      "- Label 429 corresponds to FBREL000000\n",
      "- Label 430 corresponds to FBREL003000\n",
      "- Label 431 corresponds to FBREL006000\n",
      "- Label 432 corresponds to FBREL007000\n",
      "- Label 433 corresponds to FBREL010000\n",
      "- Label 434 corresponds to FBREL032000\n",
      "- Label 435 corresponds to FBREL032010\n",
      "- Label 436 corresponds to FBREL037000\n",
      "- Label 437 corresponds to FBREL040000\n",
      "- Label 438 corresponds to FBREL040000N\n",
      "- Label 439 corresponds to FBREL050000N\n",
      "- Label 440 corresponds to FBREL053000\n",
      "- Label 441 corresponds to FBREL060000N\n",
      "- Label 442 corresponds to FBREL070000\n",
      "- Label 443 corresponds to FBSACT000000\n",
      "- Label 444 corresponds to FBSCI000000\n",
      "- Label 445 corresponds to FBSCI000000N\n",
      "- Label 446 corresponds to FBSCI003000N\n",
      "- Label 447 corresponds to FBSCI004000\n",
      "- Label 448 corresponds to FBSCI008000\n",
      "- Label 449 corresponds to FBSCI013000\n",
      "- Label 450 corresponds to FBSCI019000\n",
      "- Label 451 corresponds to FBSCI026000\n",
      "- Label 452 corresponds to FBSCI027000\n",
      "- Label 453 corresponds to FBSCI030000\n",
      "- Label 454 corresponds to FBSCI034000\n",
      "- Label 455 corresponds to FBSCI055000\n",
      "- Label 456 corresponds to FBSCI070000\n",
      "- Label 457 corresponds to FBSCI075000\n",
      "- Label 458 corresponds to FBSCI086000\n",
      "- Label 459 corresponds to FBSEL000000\n",
      "- Label 460 corresponds to FBSEL026000\n",
      "- Label 461 corresponds to FBSEL036000\n",
      "- Label 462 corresponds to FBSOC000000\n",
      "- Label 463 corresponds to FBSOC002000\n",
      "- Label 464 corresponds to FBSOC003000\n",
      "- Label 465 corresponds to FBSOC004000\n",
      "- Label 466 corresponds to FBSOC005000\n",
      "- Label 467 corresponds to FBSOC007000\n",
      "- Label 468 corresponds to FBSOC010000\n",
      "- Label 469 corresponds to FBSOC015000\n",
      "- Label 470 corresponds to FBSOC025000\n",
      "- Label 471 corresponds to FBSOC026000\n",
      "- Label 472 corresponds to FBSOC031000\n",
      "- Label 473 corresponds to FBSOC052000\n",
      "- Label 474 corresponds to FBSOC053000\n",
      "- Label 475 corresponds to FBSOC055000\n",
      "- Label 476 corresponds to FBSPO000000\n",
      "- Label 477 corresponds to FBSPO003000\n",
      "- Label 478 corresponds to FBSPO004000\n",
      "- Label 479 corresponds to FBSPO011000\n",
      "- Label 480 corresponds to FBSPO014000\n",
      "- Label 481 corresponds to FBSPO015000\n",
      "- Label 482 corresponds to FBSPO016000\n",
      "- Label 483 corresponds to FBSPO019000\n",
      "- Label 484 corresponds to FBSPO022000\n",
      "- Label 485 corresponds to FBSPO027000\n",
      "- Label 486 corresponds to FBSPO029000\n",
      "- Label 487 corresponds to FBSPO030000\n",
      "- Label 488 corresponds to FBSPO037000\n",
      "- Label 489 corresponds to FBSPO040000\n",
      "- Label 490 corresponds to FBSPO054000\n",
      "- Label 491 corresponds to FBSTU004000\n",
      "- Label 492 corresponds to FBSTU027000\n",
      "- Label 493 corresponds to FBTEC000000\n",
      "- Label 494 corresponds to FBTEC001000N\n",
      "- Label 495 corresponds to FBTEC003000\n",
      "- Label 496 corresponds to FBTEC005000\n",
      "- Label 497 corresponds to FBTEC008000\n",
      "- Label 498 corresponds to FBTEC009000\n",
      "- Label 499 corresponds to FBTEC009070\n",
      "- Label 500 corresponds to FBTEC025000\n",
      "- Label 501 corresponds to FBTEC031000\n",
      "- Label 502 corresponds to FBTRA000000\n",
      "- Label 503 corresponds to FBTRA001000\n",
      "- Label 504 corresponds to FBTRA001010\n",
      "- Label 505 corresponds to FBTRA002000\n",
      "- Label 506 corresponds to FBTRA004000\n",
      "- Label 507 corresponds to FBTRA006000\n",
      "- Label 508 corresponds to FBTRU000000\n",
      "- Label 509 corresponds to FBTRV000000\n",
      "- Label 510 corresponds to FBTRV001000N\n",
      "- Label 511 corresponds to FBTRV003000\n",
      "- Label 512 corresponds to FBTRV006000\n",
      "- Label 513 corresponds to FBTRV009000\n",
      "- Label 514 corresponds to FBTRV010000\n",
      "- Label 515 corresponds to FBTRV017000\n",
      "- Label 516 corresponds to FBTRV025000\n",
      "- Label 517 corresponds to FBTRV025040\n",
      "- Label 518 corresponds to FBTRV025070\n",
      "- Label 519 corresponds to FBTRV025090\n",
      "- Label 520 corresponds to FBTRV025110\n",
      "- Label 521 corresponds to FSHUM000000N\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, class_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(raw_train_ds):\n\u001b[1;32m      3\u001b[0m     total_cats \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Label \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m corresponds to\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mraw_train_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of CATS:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(total_cats))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "total_cats = 0\n",
    "for i, class_name in enumerate(raw_train_ds):\n",
    "    total_cats += 1\n",
    "    print(\"- Label \"+str(i)+\" corresponds to\", raw_train_ds.class_names[i])\n",
    "\n",
    "print(\"Length of CATS:\", str(total_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba58c99a-c57e-4984-bd8c-a4cdfbf6647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51567 files belonging to 522 classes.\n",
      "Using 10313 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    newpath_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    label_mode='categorical', # para CategoricalCrossentropy\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0ab2a5-9fc6-4810-9876-13373269ef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9637 files belonging to 519 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    newpath_test,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical' # CategoricalCrossentropy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed0ba62-7f03-4524-9976-e82ff261fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa5f14aa-b502-4ddf-a40f-3631848f71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 12000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    split=\"whitespace\",\n",
    "    max_tokens=max_features,\n",
    "    pad_to_max_tokens=True,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57eb833c-7751-410e-903f-9c7584fea871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train_text: <_MapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>\n",
      ">> vectorize_layer adapted: <TextVectorization name=text_vectorization, built=False>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 07:45:01.691043: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "print(\">> train_text: \"+str(train_text))\n",
    "vectorize_layer.adapt(train_text)\n",
    "print(\">> vectorize_layer adapted: \"+str(vectorize_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e45e07-3a8f-4dc0-9a2a-4aa9c01a01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b17a37f9-4247-43ce-a533-f1eb8a932b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> text_batch[0]: tf.Tensor(b'Creative Montreal  PlateauMontRoyal Guides de voyage Ulysse  Jerome Delgado  The Guide to Creative Montrals PlateauMontRoyal tour offers a foray into the fields of performing arts visual arts art galleries and public artworks digital arts music and design The tour crisscrosses the PlateauMontRoyal neighbourhood providing information on a wealth of cultural attractions including five of the most distinguished theatres in the city several wellknown galleries a panoply of live venues and some of the best public art in the city as well as countless bookstores record stores cafes restaurants and shops where you can stop along the way\\n', shape=(), dtype=string)\n",
      ">> label_batch[0]: tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(522,), dtype=float32)\n",
      "Review tf.Tensor(b'Creative Montreal  PlateauMontRoyal Guides de voyage Ulysse  Jerome Delgado  The Guide to Creative Montrals PlateauMontRoyal tour offers a foray into the fields of performing arts visual arts art galleries and public artworks digital arts music and design The tour crisscrosses the PlateauMontRoyal neighbourhood providing information on a wealth of cultural attractions including five of the most distinguished theatres in the city several wellknown galleries a panoply of live venues and some of the best public art in the city as well as countless bookstores record stores cafes restaurants and shops where you can stop along the way\\n', shape=(), dtype=string)\n",
      "Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
      "array([[  596,  6209,     1,   851,   360,  3140,  8276,  8588,     1,\n",
      "            2,    67,     5,   596,     1,     1,  1094,   142,     6,\n",
      "        11635,    50,     2,  1400,     4,  2973,  1037,  1360,  1037,\n",
      "          156,  9138,     3,   266,  9524,   125,  1037,   268,     3,\n",
      "          463,     2,  1094,     1,     2,     1,     1,   864,   164,\n",
      "           13,     6,  1012,     4,   339,  5860,   119,   451,     4,\n",
      "            2,    49,  2438, 10628,     7,     2,   228,   767,  2716,\n",
      "         9138,     6,     1,     4,   275, 10188,     3,   102,     4,\n",
      "            2,    97,   266,   156,     7,     2,   228,    12,    93,\n",
      "           12,  2296,     1,  1161,  5233,     1,  4092,     3,  5967,\n",
      "          112,    22,    45,   705,   300,     2,    83,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0]])>, <tf.Tensor: shape=(522,), dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "print(\">> text_batch[0]: \"+str(text_batch[0]))\n",
    "print(\">> label_batch[0]: \"+str(label_batch[0]))\n",
    "\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "#print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1596cb24-5d6b-45f5-a255-170dec6fbb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287 --->  brothers\n",
      " 313 --->  comprehensive\n",
      "Vocabulary size: 12000\n"
     ]
    }
   ],
   "source": [
    "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7835f113-c11b-4d74-8db0-8dca6c83aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6180ad7-bb9a-41e9-ac86-1fb5bc4b69a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "input_shape = (3, 210, 160, 3)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    # EXP OK7 EL MEJOR PARA CATEGORICAL (no sparseCategorical)\n",
    "    # 50 epochs: accuracy: 0.8873 - loss: 0.3639 - val_accuracy: 0.2263 - val_loss: 20.9532\n",
    "    # tf.keras.layers.Embedding(max_features, 64, name='embedding'),\n",
    "    # tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    # #tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    # tf.keras.layers.Dense(2430, activation='softmax')\n",
    "\n",
    "    # 50 epochs | accuracy: 0.8328 - loss: 0.6003 - val_accuracy: 0.1309 - val_loss: 9.2571\n",
    "    # 2 horas con 134K_no_quotes\n",
    "    # tf.keras.layers.Embedding(max_features, 256, name='embedding'),\n",
    "    # tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.Dense(2574, activation='softmax')\n",
    "\n",
    "    # 50 epochs para cats_NOSEK_50_only\n",
    "    # accuracy: 0.9870 - loss: 0.0518 - val_accuracy: 0.1746 - val_loss: 10.5990\n",
    "    tf.keras.layers.Embedding(max_features, 256, name='embedding'),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(522, activation='softmax')\n",
    "\n",
    "    # NOTA: segun https://www.kaggle.com/code/serkanpeldek/text-classification-with-embedding-conv1d\n",
    "    # es importante preprocesar el texto lo mas posible.\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d09d160-475c-4128-bd8d-725a1478e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f3d3ada-edef-443a-9973-9dbe3a437856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop training; got log keys: {}\".format(keys))\n",
    "        os.system('spd-say \"Tensorflow has finished training!\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52016a30-f30c-464a-aa97-af64ae0b4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # optimizer='adam',\n",
    "    # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # metrics=['accuracy']\n",
    "    \n",
    "    # De otra forma hay que usar CategoricalCrossentropy si son one_hot encoded\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # PRUEBA, PONER 0.01\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "782b53ea-01ac-40bc-8be8-decf2599e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m4278/6876\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.0413 - loss: 5.8782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 07:45:57.001724: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [0] vs. [12000,256]\n",
      "\t [[{{function_node __inference_one_step_on_data_298987}}{{node adam/truediv_1}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node adam/truediv_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/miniconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n\n  File \"/opt/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n\n  File \"/opt/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/33/58v_nv6j1619_26c1dh5_0540000gn/T/ipykernel_59465/2807588492.py\", line 2, in <module>\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 329, in fit\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 122, in one_step_on_iterator\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 110, in one_step_on_data\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 75, in train_step\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 279, in apply_gradients\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 340, in apply\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 390, in _backend_apply_gradients\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/optimizers/adam.py\", line 143, in update_step\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/ops/numpy.py\", line 5568, in divide\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/sparse.py\", line 778, in sparse_wrapper\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1921, in divide\n\nIncompatible shapes: [0] vs. [12000,256]\n\t [[{{node adam/truediv_1}}]] [Op:__inference_one_step_on_iterator_299042]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node adam/truediv_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/opt/miniconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n\n  File \"/opt/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n\n  File \"/opt/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/var/folders/33/58v_nv6j1619_26c1dh5_0540000gn/T/ipykernel_59465/2807588492.py\", line 2, in <module>\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 329, in fit\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 122, in one_step_on_iterator\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 110, in one_step_on_data\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 75, in train_step\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 279, in apply_gradients\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 340, in apply\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 390, in _backend_apply_gradients\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/optimizers/adam.py\", line 143, in update_step\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/ops/numpy.py\", line 5568, in divide\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/sparse.py\", line 778, in sparse_wrapper\n\n  File \"/opt/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/numpy.py\", line 1921, in divide\n\nIncompatible shapes: [0] vs. [12000,256]\n\t [[{{node adam/truediv_1}}]] [Op:__inference_one_step_on_iterator_299042]"
     ]
    }
   ],
   "source": [
    "epochs = 35\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927bbac-3eb3-4797-a157-9f2d8a8b32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(val_ds)\n",
    "#loss, accuracy = model.evaluate(test_ds) # Algo estra mal con test_ds que no se puede probar\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6d4c2-d4a9-4227-bdaa-77c00451f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bebc3a-aa3b-4a8a-a8be-c0de8d30e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85169906-f875-42c0-bc79-d2e5c4a9552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29c782-d3fe-498f-9261-080ce786ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2b145-ae75-4343-a7aa-39b8f01ce84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant([[\"Harry Potter and the Goblet of Fire | Pottermore from J.K. Rowling | J.K. Rowling | 'There will be three tasks, spaced throughout the school year, and they will test the champions in many different ways … their magical prowess - their daring - their powers of deduction - and, of course, their ability to cope with danger.'The Triwizard Tournament is to be held at Hogwarts. Only wizards who are over seventeen are allowed to enter - but that doesn't stop Harry dreaming that he will win the competition. Then at Hallowe'en, when the Goblet of Fire makes its selection, Harry is amazed to find his name is one of those that the magical cup picks out. He will face death-defying tasks, dragons and Dark wizards, but with the help of his best friends, Ron and Hermione, he might just make it through - alive!Harry Potter and the Goblet of Fire is currently the featured read in Pottermore’s Wizarding World Book Club. Sign up and join weekly Twitter discussions at WW Book Club.\"]]) \n",
    "labels = tf.constant([[\"xoxoxoxoxo\"]])\n",
    "ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "predict_testo = ds.map(vectorize_text)\n",
    "\n",
    "for text_batch, label_batch in predict_testo:\n",
    "    pre = probability_model.predict(text_batch.numpy())\n",
    "    index = np.argmax(pre)\n",
    "    print(\">> el indice es: \"+str(index))\n",
    "    print(raw_train_ds.class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c738d-6fa1-4a89-b9bf-6ee444f00825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "print(os.getcwd())\n",
    "model.save(newpath+'model_categories_134K.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da608fd-6c18-4663-8573-9e3064358a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se si este predict se deba hacer sobre las labels o sobre los textos, checar:\n",
    "# https://machinelearningmastery.com/multi-label-classification-with-deep-learning/\n",
    "# predictions = model.predict(predict_ds)\n",
    "# print(\">> largo de predictions: \"+str(len(predictions)))\n",
    "# print(\">> largo de predictions[0]: \"+str(len(predictions[0]))) # 1203? el numero maximo de categorias? (igual para las 3 predictions)\n",
    "# # no entiendo porque esta prediccion es un array de 1203 de largo -_-\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1869c6-5155-42b2-ab94-8b9c144d1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ccc61-3e9c-483c-b738-f132d1b8189c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d7a87-b579-49a7-884c-a935e225c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    model,\n",
    "    tf.keras.layers.Dense(1203, activation='softmax')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    optimizer=\"adam\", \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# model.compile(\n",
    "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# Test it with `raw_test_ds`, which yields raw strings\n",
    "loss, accuracy = export_model.evaluate(raw_val_ds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c96e1-f457-42c6-87ae-9dd8f0ecc7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
