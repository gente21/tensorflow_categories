{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72032c-f791-48f0-a45b-bd994a98bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# Creamos dir con las categorias\n",
    "newpath = './categories' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "# Folders de train y test\n",
    "newpath_train = newpath+'/train'\n",
    "newpath_test = newpath+'/test'\n",
    "\n",
    "def save_file(folder, text):\n",
    "    with open(folder, 'w') as text_file:\n",
    "        print(text, file=text_file)\n",
    "\n",
    "# Obtenemos train\n",
    "def csv_to_folders(source_file, target_folder):\n",
    "    with open(source_file) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        step = 0\n",
    "        for row in reader:\n",
    "            cat_folder = target_folder+'/'+row[0]\n",
    "            target_file = cat_folder+'/'+str(step)+'_'+row[0]+'.txt'\n",
    "            if not os.path.exists(cat_folder):\n",
    "                os.makedirs(cat_folder)\n",
    "                save_file(target_file, row[1])\n",
    "            else:\n",
    "                save_file(target_file, row[1])\n",
    "            step += 1\n",
    "\n",
    "csv_to_folders('/Users/raulrodriguez_demarque/demarque/market/cats_NOSEK_50_only.csv', newpath_train)\n",
    "csv_to_folders('/Users/raulrodriguez_demarque/demarque/market/cats_NOSEK_test_50.csv', newpath_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7a6fb-c507-4a0f-8cd2-ed1fcbaf14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    newpath_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    label_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59968852-e7db-4ecb-8332-c4883edd697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000\n",
    "sequence_length = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da9be3-6984-40ea-80a5-9235f858f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------------- SEPARATOR ----------------------------\")\n",
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(\"Text\", text_batch.numpy()[i])\n",
    "    print(\"Category\", label_batch.numpy()[i])\n",
    "print(\"----------------------- SEPARATOR ----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbcc00-2353-45e8-86c9-01604f19e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cats = 0\n",
    "for i, class_name in enumerate(raw_train_ds):\n",
    "    total_cats += 1\n",
    "    print(\"- Label \"+str(i)+\" corresponds to\", raw_train_ds.class_names[i])\n",
    "\n",
    "print(\"Length of CATS:\", str(total_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58c99a-c57e-4984-bd8c-a4cdfbf6647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    newpath_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    label_mode='categorical', # para CategoricalCrossentropy\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ab2a5-9fc6-4810-9876-13373269ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    newpath_test,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical' # CategoricalCrossentropy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0ba62-7f03-4524-9976-e82ff261fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f14aa-b502-4ddf-a40f-3631848f71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 50000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    split=\"whitespace\",\n",
    "    max_tokens=max_features,\n",
    "    pad_to_max_tokens=True,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb833c-7751-410e-903f-9c7584fea871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "print(\">> train_text: \"+str(train_text))\n",
    "vectorize_layer.adapt(train_text)\n",
    "print(\">> vectorize_layer adapted: \"+str(vectorize_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e45e07-3a8f-4dc0-9a2a-4aa9c01a01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a37f9-4247-43ce-a533-f1eb8a932b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "print(\">> text_batch[0]: \"+str(text_batch[0]))\n",
    "print(\">> label_batch[0]: \"+str(label_batch[0]))\n",
    "\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "#print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596cb24-5d6b-45f5-a255-170dec6fbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835f113-c11b-4d74-8db0-8dca6c83aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6180ad7-bb9a-41e9-ac86-1fb5bc4b69a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "input_shape = (3, 210, 160, 3)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    # EXP OK7 EL MEJOR PARA CATEGORICAL (no sparseCategorical)\n",
    "    # 50 epochs: accuracy: 0.8873 - loss: 0.3639 - val_accuracy: 0.2263 - val_loss: 20.9532\n",
    "    # tf.keras.layers.Embedding(max_features, 64, name='embedding'),\n",
    "    # tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    # #tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    # tf.keras.layers.Dense(2430, activation='softmax')\n",
    "\n",
    "    # 50 epochs | accuracy: 0.8328 - loss: 0.6003 - val_accuracy: 0.1309 - val_loss: 9.2571\n",
    "    # 2 horas con 134K_no_quotes\n",
    "    # tf.keras.layers.Embedding(max_features, 256, name='embedding'),\n",
    "    # tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "    # tf.keras.layers.Dense(2574, activation='softmax')\n",
    "\n",
    "    # 50 epochs para cats_NOSEK_50_only\n",
    "    # accuracy: 0.9870 - loss: 0.0518 - val_accuracy: 0.1746 - val_loss: 10.5990\n",
    "    # tf.keras.layers.Embedding(max_features, 256, name='embedding'),\n",
    "    # tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    # tf.keras.layers.Dropout(0.1),\n",
    "    # tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    # tf.keras.layers.Dropout(0.1),\n",
    "    # tf.keras.layers.Dense(781, activation='softmax')\n",
    "\n",
    "    # 50 epochs para cats_NOSEK_50_only\n",
    "    # accuracy: 0.9941 - loss: 0.0250 - val_accuracy: 0.1377 - val_loss: 13.9855\n",
    "    tf.keras.layers.Embedding(max_features, 256, name='embedding'),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(781, activation='softmax')\n",
    "\n",
    "    # NOTA: segun https://www.kaggle.com/code/serkanpeldek/text-classification-with-embedding-conv1d\n",
    "    # es importante preprocesar el texto lo mas posible.\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09d160-475c-4128-bd8d-725a1478e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d3ada-edef-443a-9973-9dbe3a437856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop training; got log keys: {}\".format(keys))\n",
    "        os.system('spd-say \"Tensorflow has finished training!\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52016a30-f30c-464a-aa97-af64ae0b4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # optimizer='adam',\n",
    "    # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # metrics=['accuracy']\n",
    "    \n",
    "    # De otra forma hay que usar CategoricalCrossentropy si son one_hot encoded\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # PRUEBA, PONER 0.01\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b53ea-01ac-40bc-8be8-decf2599e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927bbac-3eb3-4797-a157-9f2d8a8b32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(val_ds)\n",
    "#loss, accuracy = model.evaluate(test_ds) # Algo estra mal con test_ds que no se puede probar\n",
    "# CREO QUE ES PORQUE EL TEST NO TIENE EL MISMO NUMERO DE CATEGORIAS (classes)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6d4c2-d4a9-4227-bdaa-77c00451f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bebc3a-aa3b-4a8a-a8be-c0de8d30e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85169906-f875-42c0-bc79-d2e5c4a9552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29c782-d3fe-498f-9261-080ce786ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2b145-ae75-4343-a7aa-39b8f01ce84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.constant([[\"The Death of Holden Hachette Australia Royce Kurmelovs Holden is one of the few brands that has an emotional grip on Australia (Qantas being another). The closure of the Holden factory in Adelaide is not just the end of a business - it's the end of an era, of a story, and of a great Australian dream.When Holden signalled that it would close its Adelaide factory, it struck at the very heart of Australian identity. Holden is our car made on our shores. It's the choice of patriotic rev heads and suburban drivers alike. How could a car that was so beloved - and so popular - be so unprofitable to make?The story of the collapse of Holden is about the people who make and drive the cars; it's about sustaining industry in Australia; it's about communities of workers and what happens when the work dries up. And if it's not quite about the death of an icon - because Holdens will remain on Australian roads for a long time to come - then it's about what happens when an icon falls to knees in front of a whole nation.'Brilliant and powerful' Nick Xenophon\"]]) \n",
    "labels = tf.constant([[\"xoxoxoxoxo\"]])\n",
    "ds = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "predict_testo = ds.map(vectorize_text)\n",
    "\n",
    "for text_batch, label_batch in predict_testo:\n",
    "    pre = probability_model.predict(text_batch.numpy())\n",
    "    index = np.argmax(pre)\n",
    "    print(\">> el indice es: \"+str(index))\n",
    "    print(raw_train_ds.class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c738d-6fa1-4a89-b9bf-6ee444f00825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "print(os.getcwd())\n",
    "model.save(newpath+'model_categories_50K.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da608fd-6c18-4663-8573-9e3064358a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se si este predict se deba hacer sobre las labels o sobre los textos, checar:\n",
    "# https://machinelearningmastery.com/multi-label-classification-with-deep-learning/\n",
    "# predictions = model.predict(predict_ds)\n",
    "# print(\">> largo de predictions: \"+str(len(predictions)))\n",
    "# print(\">> largo de predictions[0]: \"+str(len(predictions[0]))) # 1203? el numero maximo de categorias? (igual para las 3 predictions)\n",
    "# # no entiendo porque esta prediccion es un array de 1203 de largo -_-\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1869c6-5155-42b2-ab94-8b9c144d1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ccc61-3e9c-483c-b738-f132d1b8189c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d7a87-b579-49a7-884c-a935e225c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    model,\n",
    "    tf.keras.layers.Dense(1203, activation='softmax')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    optimizer=\"adam\", \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# model.compile(\n",
    "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# Test it with `raw_test_ds`, which yields raw strings\n",
    "loss, accuracy = export_model.evaluate(raw_val_ds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c96e1-f457-42c6-87ae-9dd8f0ecc7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
